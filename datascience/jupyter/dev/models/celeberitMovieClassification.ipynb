{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "# Configure Environment \nfrom  dev.data.settings import * \nprint(\"Platform: \" , PLATFORM)\nprint(\"Data directory : \", os.getcwd())\n\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Platform:  dev\nData directory :  /home/jovyan/dev/data\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import os\nimport sys\nimport time\nimport logging\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport urllib.parse\nimport http.client\nimport json\nimport pickle\nimport logging\nlogger = logging.getLogger('personCasting')\nlogger.setLevel(logging.INFO)", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import numpy as np\nimport nltk\nfrom nltk.stem import PorterStemmer\n\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('punkt')\nstopwords=  set(stopwords.words('english'))\n\nfrom nltk.tokenize import RegexpTokenizer", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Extract Movies Plots for each Celebrity by genre.  \n* Combine all plots across movies into one text\n"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "path_to_json = './cast/themoviedb/'\njson_files = [path_to_json+pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json') ]\nlen(json_files)\n\ntheMovieDB=[]\nfor fname in json_files:\n    try:\n        with open(fname, 'r') as f:\n            r = json.load(f)   \n            for row in r:\n                theMovieDB.append(row)\n\n    except Exception as e:\n        #extract.update({ columns[key]  : '' } )\n        logger.info('Unable to find key : '+ fname + '::' +str(e))        \n        ", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "theMovieDB=[]\nfor fname in json_files:\n    try:\n        with open(fname, 'r') as f:\n            r = json.load(f)   \n            for row in r:\n                theMovieDB.append(row)\n\n    except Exception as e:\n        #extract.update({ columns[key]  : '' } )\n        logger.info('Unable to find key : '+ fname + '::' +str(e))        \n        \ncastDF =  pd.DataFrame.from_dict(theMovieDB , dtype=str)\ncastDF.head()        ", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "path_to_json = './movies/wikipedia/'\njson_files = [path_to_json+pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json') and os.stat(path_to_json+pos_json).st_size>0]\nlen(json_files)\n\nmoviesPlot=[]\n\nfor fname in json_files:\n    with open(fname, 'r') as f:\n        r = json.load(f)   \n        columns= {'_movieID': '_movieID', 'plot': 'plot', 'summary': 'summary' }\n        \n        extract ={}\n        for key in columns:\n            try: \n                extract.update({ columns[key] : r[key] } )\n            except Exception as e:\n                extract.update({ columns[key]  : '' } )\n                logger.info('Unable to find key : '+ key + '::' +str(e))\n\n        moviesPlot.append(extract)\n    \nplotDF =  pd.DataFrame.from_dict(moviesPlot , dtype=str)\nplotDF[plotDF['plot']==''].head()  ", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "path_to_json = './movies/imdb/'\njson_files = [path_to_json+pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json') and os.stat(path_to_json+pos_json).st_size>0]\nlen(json_files)\n\nmovieGenre =[]\n\nfor fname in json_files:\n    with open(fname, 'r') as f:\n        r = json.load(f)   \n        columns= {'_id': '_movieID', 'plot outline': 'plot', 'genres': 'genres' }\n        \n        extract ={}\n        for key in columns:\n            try: \n                if key == 'genres':\n                    extract.update({'genres': ','.join(r[key]) })\n                else:\n                    extract.update({ columns[key] : r[key] } )\n            except Exception as e:\n                extract.update({ columns[key]  : '' } )\n                logger.info('Unable to find key : '+ key + '::' +str(e))\n\n        movieGenre.append(extract)\n    \nmovieGenreDF =  pd.DataFrame.from_dict(movieGenre , dtype=str)\nmovieGenreDF.head()   ", "execution_count": 12, "outputs": []}, {"metadata": {"trusted": true, "scrolled": true}, "cell_type": "code", "source": "castDF['movieID'] = castDF['movieID'].astype(str)\ncastMoivesDF = castDF.merge( plotDF, how='inner', left_on = 'movieID', right_on = '_movieID')\ncastMoivesDF = castMoivesDF.merge( movieGenreDF, how='inner', left_on = '_movieID', right_on = '_movieID')\n\ncastMoivesDF['plotCombine'] = castMoivesDF['movieTitle']+ ' '+ castMoivesDF['plot_x']+' '+castMoivesDF['summary']+' '+castMoivesDF['plot_y']\nextractDF=castMoivesDF[['_actorID', 'actor', '_movieID', 'plotCombine', 'genres']]\n\n\n# Combine all the movie plots from different data sources into one field\n# Given a moive can belong into multiple genre, create row for each movie plot\n\nextractDF = extractDF['genres'].str.split(',').apply(pd.Series) \\\n.merge(extractDF, right_index = True, left_index=True) \\\n.drop(['genres'], axis =1) \\\n.melt(id_vars =['_actorID', 'actor', '_movieID', 'plotCombine'], value_name='genre') \\\n.drop('variable', axis=1) \\\n.dropna()\n\n# Combine all the different movie plots by actor and genre.\n\nactorGenreSummary = extractDF.groupby(['_actorID', 'actor', 'genre'])['plotCombine'].apply(lambda x: ' '.join(x)).reset_index()\n\n# Get counts by genre\nextractDF.groupby('genre').count()", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "  _actorID           actor _movieID  \\\n0        5  Bradley Cooper    28355   \n1        5  Bradley Cooper    45243   \n2        5  Bradley Cooper    18785   \n3        5  Bradley Cooper    97367   \n4        5  Bradley Cooper   109439   \n\n                                         plotCombine                   genres  \n0  Case 39 Emily Jenkins (Ren\u00e9e Zellweger) is a s...  Horror,Mystery,Thriller  \n1  The Hangover Part II Two years after the event...           Comedy,Mystery  \n2  The Hangover To celebrate his upcoming marriag...                   Comedy  \n3  The Place Beyond the Pines In 1997, Luke Glant...     Crime,Drama,Thriller  \n4  The Hangover Part III Two years after the even...   Adventure,Comedy,Crime  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_actorID</th>\n      <th>actor</th>\n      <th>_movieID</th>\n      <th>plotCombine</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>Bradley Cooper</td>\n      <td>28355</td>\n      <td>Case 39 Emily Jenkins (Ren\u00e9e Zellweger) is a s...</td>\n      <td>Horror,Mystery,Thriller</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>Bradley Cooper</td>\n      <td>45243</td>\n      <td>The Hangover Part II Two years after the event...</td>\n      <td>Comedy,Mystery</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>Bradley Cooper</td>\n      <td>18785</td>\n      <td>The Hangover To celebrate his upcoming marriag...</td>\n      <td>Comedy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>Bradley Cooper</td>\n      <td>97367</td>\n      <td>The Place Beyond the Pines In 1997, Luke Glant...</td>\n      <td>Crime,Drama,Thriller</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Bradley Cooper</td>\n      <td>109439</td>\n      <td>The Hangover Part III Two years after the even...</td>\n      <td>Adventure,Comedy,Crime</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Get a list of generes\n\n', '.join(extractDF['genre'].unique().tolist())", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "'Horror, Comedy, Crime, Adventure, Action, Drama, Documentary, Short, Animation, Music, Biography, Sport, Family, , Fantasy, Romance, Game-Show, Musical, Mystery, Thriller, Reality-TV, Sci-Fi, History, War, Western, News, Film-Noir'"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "actorGenreCatalog = actorGenreSummary.to_json(orient='records')\nactorGenreJson = eval(actorGenreCatalog)\n\n# Save model lookup \npickle.dump( actorGenreJson, open( \"./models/actorGenreDict.pkl\", \"wb\" ) )", "execution_count": 22, "outputs": [{"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "1228"}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "markdown", "source": "# Clean final Plot Text "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def tokenizeDoc(docs, stopwords=stopwords ):\n    i=0\n    for doc in docs:\n        tokenizer = RegexpTokenizer(r'\\w+')\n        tokens = tokenizer.tokenize(doc.lower())\n        # Stem words\n        #ps = PorterStemmer()\n        #tokens = [ps.stem(word) for word in tokens]\n        # Remove stop words.\n        tokens = [word for word in tokens if word not in stopwords]\n        fdist1 = nltk.FreqDist(tokens)\n        words = list(word for word, freq in fdist1.items() if not word.isdigit())\n\n        docs[i] = ' '.join(words[:3000])\n        i += 1\n    return docs", "execution_count": 25, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def cleanSentences(sentences):\n    punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'  #TBD\n        #TBD - find sentence splitter - \n        # remove punctuation, strip white space; remove non-standard characters; remove numbers; \n    i = 0\n    for s in sentences:\n        s = s.strip()\n        s = s.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ').replace(\"[0-9]\", \" \")\n        s = s.replace(',', '').replace('.','') #TBD - replace with punctuation\n        #s = s[0:2000]\n        sentences[i] = s\n        i += 1\n    return sentences", "execution_count": 26, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "sentencesAll = actorGenreSummary['plotCombine'].tolist()\nlen(sentencesAll) \nsentences = tokenizeDoc(sentencesAll)\nsentences[1]", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Start ELMo Word Embedding Modeling"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import tensorflow.compat.v1 as tf\nimport tensorflow_hub as hub\n\nconfig = tf.ConfigProto()\nconfig.intra_op_parallelism_threads = 200\nconfig.gpu_options.allow_growth = True\ntf.Session(config=config)\n\n\nurl = \"https://tfhub.dev/google/elmo/2\"\nembed = hub.Module(url)\n\nelmodir = os.getcwd()+'/models/'", "execution_count": 29, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def embed_text(text):\n    vectors = session.run(embeddings, feed_dict={text_ph: text})\n    return [vector.tolist() for vector in vectors]", "execution_count": 30, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# score n Sentences at time - to pipeline this\ndef defineEmbeddings (start, end):    \n    embeddings = embed(\n        sentences[start:end],\n        signature=\"default\",\n        as_dict=True)[\"default\"]\n    return embeddings# Save Weights - use names based on Movie \n\nimport pickle as pkl\n# score sentences\ndef scoreSentences (embeddings):\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.tables_initializer())\n        x = sess.run(embeddings)\n    return x\n\ndef saveWeights(elmoFN, x):\n    with open('./models/'+elmoFN,'wb') as f: pkl.dump(x, f)\n    return", "execution_count": 31, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import math \n\nbatch_size = 50                    \nnumPlots = len(sentences)\nnumfiles = math.ceil(numPlots/batch_size) \nprint('No of expected Elmo Weigh files : ', str(numfiles))\n\nstart = 0\nend = batch_size\nfor file in range(1,numfiles+1):\n    elmoFN = 'elmoPlotsweights' + str(start) + 'to' + str(end) + '.pkl'\n    print('Score sentences:', elmoFN)\n\n        # Define Embeddings, Score, and Store Weights one Batch of N at time\n    embeddings = defineEmbeddings(start, end)\n    x = scoreSentences(embeddings)\n    saveWeights(elmoFN,x)\n    start = end\n    end = end+batch_size", "execution_count": 32, "outputs": [{"output_type": "stream", "text": "No of expected Elmo Weigh files :  25\nScore sentences: elmoPlotsweights0to50.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights50to100.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights100to150.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights150to200.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights200to250.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights250to300.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights300to350.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights350to400.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights400to450.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights450to500.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights500to550.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights550to600.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights600to650.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights650to700.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights700to750.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights750to800.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights800to850.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights850to900.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights900to950.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights950to1000.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights1000to1050.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights1050to1100.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights1100to1150.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights1150to1200.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}, {"output_type": "stream", "text": "Score sentences: elmoPlotsweights1200to1250.pkl\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "\nimport pickle as pkl\nimport numpy as np\nimport glob\n\ndef readElmoWeightFile(file):\n    with open(elmodir+file, 'rb') as f:\n        elmo_file = pkl.load(f)\n    return list(elmo_file)\n  \ndef readWeights(elmodir, modelname):\n    noFiles = len([name for name in os.listdir(elmodir) if modelname in name ])\n    xin = readElmoWeightFile('elmoPlotsweights0to'+str(batch_size)+'.pkl')\n    size = batch_size\n    for x in range(1, noFiles):\n        start = x*size\n        end = start+size\n        filename = 'elmoPlotsweights' + str(start) + 'to' + str(end) + '.pkl'\n        print(filename)\n        xin += readElmoWeightFile(filename)\n    return xin", "execution_count": 39, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "!ls models/", "execution_count": 42, "outputs": [{"output_type": "stream", "text": "actorGenreDict.pkl\t\telmoPlotsweights300to350.pkl\r\nactorGenreVect.pkl\t\telmoPlotsweights350to400.pkl\r\nbio_dict.pkl\t\t\telmoPlotsweights400to450.pkl\r\ncelebrityBio.json\t\telmoPlotsweights450to500.pkl\r\ncelebrityLookup.pkl\t\telmoPlotsweights500to550.pkl\r\nelmoBioweights0to100.pkl\telmoPlotsweights50to100.pkl\r\nelmoBioweights.pkl\t\telmoPlotsweights550to600.pkl\r\nelmoPlotsweights0to50.pkl\telmoPlotsweights600to650.pkl\r\nelmoPlotsweights1000to1050.pkl\telmoPlotsweights650to700.pkl\r\nelmoPlotsweights100to150.pkl\telmoPlotsweights700to750.pkl\r\nelmoPlotsweights1050to1100.pkl\telmoPlotsweights750to800.pkl\r\nelmoPlotsweights1100to1150.pkl\telmoPlotsweights800to850.pkl\r\nelmoPlotsweights1150to1200.pkl\telmoPlotsweights850to900.pkl\r\nelmoPlotsweights1200to1250.pkl\telmoPlotsweights900to950.pkl\r\nelmoPlotsweights150to200.pkl\telmoPlotsweights950to1000.pkl\r\nelmoPlotsweights200to250.pkl\tgenreStats.pkl\r\nelmoPlotsweights250to300.pkl\r\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Export Dictonary and GenrePlot Vectors\nimport pickle\nxin = readWeights(elmodir, 'Plot')\nprint(\"Elmo Vector Shape {0}, {1}\".format( len(xin), len(xin[1])) )\n\npickle.dump( actorGenreJson, open( \"./models/actorGenreDict.pkl\", \"wb\" ) )\npickle.dump( xin, open( \"./models/actorGenreVect.pkl\", \"wb\" ) )\n", "execution_count": 41, "outputs": [{"output_type": "stream", "text": "elmoPlotsweights50to100.pkl\nelmoPlotsweights100to150.pkl\nelmoPlotsweights150to200.pkl\nelmoPlotsweights200to250.pkl\nelmoPlotsweights250to300.pkl\nelmoPlotsweights300to350.pkl\nelmoPlotsweights350to400.pkl\nelmoPlotsweights400to450.pkl\nelmoPlotsweights450to500.pkl\nelmoPlotsweights500to550.pkl\nelmoPlotsweights550to600.pkl\nelmoPlotsweights600to650.pkl\nelmoPlotsweights650to700.pkl\nelmoPlotsweights700to750.pkl\nelmoPlotsweights750to800.pkl\nelmoPlotsweights800to850.pkl\nelmoPlotsweights850to900.pkl\nelmoPlotsweights900to950.pkl\nelmoPlotsweights950to1000.pkl\nelmoPlotsweights1000to1050.pkl\nelmoPlotsweights1050to1100.pkl\nelmoPlotsweights1100to1150.pkl\nelmoPlotsweights1150to1200.pkl\nelmoPlotsweights1200to1250.pkl\nElmo Vector Shape 1228, 1024\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Copy models up to S3 bucket\nbucket = os.popen('aws ssm get-parameter --name jupyterBucketName-' + PLATFORM + ' --with-decryption | jq -r .Parameter.Value').read()\nprint(bucket)\nexecutable = 'aws s3 sync ./models/ s3://' + bucket.strip() + '/models/ '\nprint(executable)\nmyCmd = os.popen(executable).read()\nprint(myCmd)", "execution_count": 45, "outputs": [{"output_type": "stream", "text": "bdso-celebrity-content-dev-vpc-05447d97de18e28f8\n\naws s3 sync ./models/ s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/ \nCompleted 256.0 KiB/16.7 MiB (2.2 MiB/s) with 22 file(s) remaining\nCompleted 512.0 KiB/16.7 MiB (4.1 MiB/s) with 22 file(s) remaining\nCompleted 657.0 KiB/16.7 MiB (5.1 MiB/s) with 22 file(s) remaining\nCompleted 913.0 KiB/16.7 MiB (6.3 MiB/s) with 22 file(s) remaining\nCompleted 925.7 KiB/16.7 MiB (6.3 MiB/s) with 22 file(s) remaining\nupload: models/celebrityBio.json to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/celebrityBio.json\nCompleted 925.7 KiB/16.7 MiB (6.3 MiB/s) with 21 file(s) remaining\nCompleted 1.2 MiB/16.7 MiB (7.8 MiB/s) with 21 file(s) remaining  \nCompleted 1.4 MiB/16.7 MiB (9.2 MiB/s) with 21 file(s) remaining  \nCompleted 1.6 MiB/16.7 MiB (10.3 MiB/s) with 21 file(s) remaining \nupload: models/elmoPlotsweights1000to1050.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights1000to1050.pkl\nCompleted 1.6 MiB/16.7 MiB (10.3 MiB/s) with 20 file(s) remaining\nCompleted 1.8 MiB/16.7 MiB (11.2 MiB/s) with 20 file(s) remaining\nupload: models/elmoPlotsweights300to350.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights300to350.pkl\nCompleted 1.8 MiB/16.7 MiB (11.2 MiB/s) with 19 file(s) remaining\nCompleted 2.0 MiB/16.7 MiB (12.6 MiB/s) with 19 file(s) remaining\nCompleted 2.3 MiB/16.7 MiB (13.8 MiB/s) with 19 file(s) remaining\nCompleted 2.5 MiB/16.7 MiB (14.7 MiB/s) with 19 file(s) remaining\nCompleted 2.7 MiB/16.7 MiB (15.1 MiB/s) with 19 file(s) remaining\nupload: models/elmoPlotsweights1200to1250.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights1200to1250.pkl\nCompleted 2.7 MiB/16.7 MiB (15.1 MiB/s) with 18 file(s) remaining\nCompleted 2.9 MiB/16.7 MiB (15.9 MiB/s) with 18 file(s) remaining\nCompleted 3.1 MiB/16.7 MiB (16.8 MiB/s) with 18 file(s) remaining\nupload: models/elmoPlotsweights1050to1100.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights1050to1100.pkl\nCompleted 3.1 MiB/16.7 MiB (16.8 MiB/s) with 17 file(s) remaining\nCompleted 3.3 MiB/16.7 MiB (17.5 MiB/s) with 17 file(s) remaining\nCompleted 3.5 MiB/16.7 MiB (18.1 MiB/s) with 17 file(s) remaining\nupload: models/elmoPlotsweights1150to1200.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights1150to1200.pkl\nCompleted 3.5 MiB/16.7 MiB (18.1 MiB/s) with 16 file(s) remaining\nCompleted 3.8 MiB/16.7 MiB (19.0 MiB/s) with 16 file(s) remaining\nCompleted 4.0 MiB/16.7 MiB (19.3 MiB/s) with 16 file(s) remaining\nupload: models/elmoPlotsweights500to550.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights500to550.pkl\nCompleted 4.0 MiB/16.7 MiB (19.3 MiB/s) with 15 file(s) remaining\nCompleted 4.2 MiB/16.7 MiB (19.8 MiB/s) with 15 file(s) remaining\nCompleted 4.5 MiB/16.7 MiB (20.7 MiB/s) with 15 file(s) remaining\nCompleted 4.7 MiB/16.7 MiB (21.4 MiB/s) with 15 file(s) remaining\nupload: models/elmoPlotsweights350to400.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights350to400.pkl\nCompleted 4.7 MiB/16.7 MiB (21.4 MiB/s) with 14 file(s) remaining\nCompleted 4.9 MiB/16.7 MiB (21.6 MiB/s) with 14 file(s) remaining\nCompleted 5.2 MiB/16.7 MiB (22.7 MiB/s) with 14 file(s) remaining\nCompleted 5.4 MiB/16.7 MiB (23.6 MiB/s) with 14 file(s) remaining\nCompleted 5.7 MiB/16.7 MiB (24.5 MiB/s) with 14 file(s) remaining\nCompleted 5.9 MiB/16.7 MiB (25.1 MiB/s) with 14 file(s) remaining\nupload: models/elmoPlotsweights550to600.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights550to600.pkl\nCompleted 5.9 MiB/16.7 MiB (25.1 MiB/s) with 13 file(s) remaining\nCompleted 6.1 MiB/16.7 MiB (25.4 MiB/s) with 13 file(s) remaining\nupload: models/elmoPlotsweights400to450.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights400to450.pkl\nCompleted 6.1 MiB/16.7 MiB (25.4 MiB/s) with 12 file(s) remaining\nCompleted 6.3 MiB/16.7 MiB (25.9 MiB/s) with 12 file(s) remaining\nCompleted 6.6 MiB/16.7 MiB (26.7 MiB/s) with 12 file(s) remaining\nCompleted 6.8 MiB/16.7 MiB (27.5 MiB/s) with 12 file(s) remaining\nCompleted 7.1 MiB/16.7 MiB (28.2 MiB/s) with 12 file(s) remaining\nCompleted 7.3 MiB/16.7 MiB (28.8 MiB/s) with 12 file(s) remaining\nupload: models/elmoPlotsweights650to700.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights650to700.pkl\nCompleted 7.3 MiB/16.7 MiB (28.8 MiB/s) with 11 file(s) remaining\nCompleted 7.5 MiB/16.7 MiB (28.9 MiB/s) with 11 file(s) remaining\nCompleted 7.7 MiB/16.7 MiB (29.2 MiB/s) with 11 file(s) remaining\nupload: models/elmoPlotsweights700to750.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights700to750.pkl\nCompleted 7.7 MiB/16.7 MiB (29.2 MiB/s) with 10 file(s) remaining\nCompleted 8.0 MiB/16.7 MiB (29.9 MiB/s) with 10 file(s) remaining\nCompleted 8.2 MiB/16.7 MiB (29.9 MiB/s) with 10 file(s) remaining\nCompleted 8.5 MiB/16.7 MiB (30.7 MiB/s) with 10 file(s) remaining\nCompleted 8.7 MiB/16.7 MiB (31.2 MiB/s) with 10 file(s) remaining\nupload: models/elmoPlotsweights800to850.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights800to850.pkl\nCompleted 8.7 MiB/16.7 MiB (31.2 MiB/s) with 9 file(s) remaining\nCompleted 8.9 MiB/16.7 MiB (31.4 MiB/s) with 9 file(s) remaining\nupload: models/elmoPlotsweights1100to1150.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights1100to1150.pkl\nCompleted 8.9 MiB/16.7 MiB (31.4 MiB/s) with 8 file(s) remaining\nCompleted 9.1 MiB/16.7 MiB (31.7 MiB/s) with 8 file(s) remaining\nCompleted 9.4 MiB/16.7 MiB (32.4 MiB/s) with 8 file(s) remaining\nCompleted 9.6 MiB/16.7 MiB (32.6 MiB/s) with 8 file(s) remaining\nCompleted 9.9 MiB/16.7 MiB (33.4 MiB/s) with 8 file(s) remaining\nCompleted 10.1 MiB/16.7 MiB (33.5 MiB/s) with 8 file(s) remaining\nupload: models/elmoPlotsweights600to650.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights600to650.pkl\nCompleted 10.1 MiB/16.7 MiB (33.5 MiB/s) with 7 file(s) remaining\nCompleted 10.3 MiB/16.7 MiB (33.9 MiB/s) with 7 file(s) remaining\nCompleted 10.6 MiB/16.7 MiB (34.6 MiB/s) with 7 file(s) remaining\nCompleted 10.8 MiB/16.7 MiB (35.1 MiB/s) with 7 file(s) remaining\nCompleted 11.1 MiB/16.7 MiB (35.8 MiB/s) with 7 file(s) remaining\nCompleted 11.3 MiB/16.7 MiB (36.0 MiB/s) with 7 file(s) remaining\nupload: models/elmoPlotsweights900to950.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights900to950.pkl\nCompleted 11.3 MiB/16.7 MiB (36.0 MiB/s) with 6 file(s) remaining\nCompleted 11.4 MiB/16.7 MiB (36.3 MiB/s) with 6 file(s) remaining\nupload: models/elmoPlotsweights850to900.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights850to900.pkl\nCompleted 11.4 MiB/16.7 MiB (36.3 MiB/s) with 5 file(s) remaining\nCompleted 11.7 MiB/16.7 MiB (37.0 MiB/s) with 5 file(s) remaining\nCompleted 11.9 MiB/16.7 MiB (37.7 MiB/s) with 5 file(s) remaining\nCompleted 12.2 MiB/16.7 MiB (38.2 MiB/s) with 5 file(s) remaining\nCompleted 12.4 MiB/16.7 MiB (38.8 MiB/s) with 5 file(s) remaining\nCompleted 12.6 MiB/16.7 MiB (39.0 MiB/s) with 5 file(s) remaining\nupload: models/elmoPlotsweights450to500.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights450to500.pkl\nCompleted 12.6 MiB/16.7 MiB (39.0 MiB/s) with 4 file(s) remaining\nCompleted 12.9 MiB/16.7 MiB (39.6 MiB/s) with 4 file(s) remaining\nCompleted 13.1 MiB/16.7 MiB (40.3 MiB/s) with 4 file(s) remaining\nCompleted 13.4 MiB/16.7 MiB (40.8 MiB/s) with 4 file(s) remaining\nCompleted 13.6 MiB/16.7 MiB (41.3 MiB/s) with 4 file(s) remaining\nCompleted 13.9 MiB/16.7 MiB (41.8 MiB/s) with 4 file(s) remaining\nCompleted 14.1 MiB/16.7 MiB (42.3 MiB/s) with 4 file(s) remaining\nCompleted 14.4 MiB/16.7 MiB (42.7 MiB/s) with 4 file(s) remaining\nCompleted 14.6 MiB/16.7 MiB (43.2 MiB/s) with 4 file(s) remaining\nCompleted 14.9 MiB/16.7 MiB (43.7 MiB/s) with 4 file(s) remaining\nCompleted 15.1 MiB/16.7 MiB (44.2 MiB/s) with 4 file(s) remaining\nCompleted 15.4 MiB/16.7 MiB (44.7 MiB/s) with 4 file(s) remaining\nCompleted 15.6 MiB/16.7 MiB (45.2 MiB/s) with 4 file(s) remaining\nCompleted 15.9 MiB/16.7 MiB (45.6 MiB/s) with 4 file(s) remaining\nCompleted 16.1 MiB/16.7 MiB (46.0 MiB/s) with 4 file(s) remaining\nCompleted 16.3 MiB/16.7 MiB (45.7 MiB/s) with 4 file(s) remaining\nupload: models/elmoPlotsweights950to1000.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights950to1000.pkl\nCompleted 16.3 MiB/16.7 MiB (45.7 MiB/s) with 3 file(s) remaining\nCompleted 16.5 MiB/16.7 MiB (44.7 MiB/s) with 3 file(s) remaining\nupload: models/elmoPlotsweights750to800.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/elmoPlotsweights750to800.pkl\nCompleted 16.5 MiB/16.7 MiB (44.7 MiB/s) with 2 file(s) remaining\nCompleted 16.7 MiB/16.7 MiB (43.9 MiB/s) with 2 file(s) remaining\nupload: models/actorGenreVect.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/actorGenreVect.pkl\nCompleted 16.7 MiB/16.7 MiB (43.9 MiB/s) with 1 file(s) remaining\nupload: models/actorGenreDict.pkl to s3://bdso-celebrity-content-dev-vpc-05447d97de18e28f8/models/actorGenreDict.pkl\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Push Model to Production"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import pickle\n\nactorGenreJson = pickle.load( open( './models/actorGenreDict.pkl', 'rb' ) )\nxin = pickle.load( open( './models/actorGenreVect.pkl', 'rb' ) )\n", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Test Elasticsearch to store the vertor and peform cosine similarity score.\n"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import requests\nfrom pprint import pprint\nfrom datetime import datetime\nfrom elasticsearch import Elasticsearch\nimport json\n\n\n_index='genresplot'\nesIndex = 'http://'+ESHOST+':'+ESPORT+'/'+_index  \nes=Elasticsearch([{'host':ESHOST,'port':ESPORT}])\n\n_doc= 'genreplot'\n\nheaders={\"Content-Type\": \"application/json\"}", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "request_body = {\n  \"mappings\": {\n    \"properties\": {\n      \"_actorID\" : {\n        \"type\" : \"keyword\"\n      },     \n      \"celebrity\" : {\n        \"type\" : \"keyword\"\n      }, \n      \"genre\" : {\n        \"type\" : \"keyword\"\n      }, \n                \n      \"genre_vector\": {\n        \"type\": \"dense_vector\",\n        \"dims\": 1024\n      }\n\n    }\n  }\n}\n\ntry:\n    es.indices.delete(index = _index)\nexcept:\n    pass\n    \nes.indices.create(index = _index, body = request_body)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "actorGenreJson[0]", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# Load Facail data into ES\nfor i in range(len(actorGenreJson)):\n    actorGenre =actorGenreJson[i]\n    _id = actorGenre['_actorID']+'-'+actorGenre['genre']\n    #print(_id)\n    doc = {\n        \"_actorID\" : actorGenre['_actorID'],\n        \"celebrity\": actorGenre['actor'],\n        \"genre\": actorGenre['genre'],\n        \"genre_vector\": [float(x) for x in xin[i]]\n        }\n    r = requests.put(esIndex+'/_doc/'+_id, headers= headers, data = json.dumps(doc))\n    print (r.text)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def getCelbGenre( celebrity): \n    q={\n      \"_source\": {\n        \"includes\": [ \"genre\"]\n        },\n      \"query\": { \n        \"bool\": { \n          \"must\": [\n            { \"match\": { \"celebrity\":celebrity}}\n          ]\n        }\n      }\n    }\n    res= es.search(index=_index, body=json.dumps(q))\n    if res['hits']['hits']:\n        results=[]\n        matches = res['hits']['hits']\n        for match in matches:\n            results.append(match['_source']['genre'])\n        return results\n    else:\n        return None\n            \n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def getCelbGenreVec( celebrity, genre): \n    q={\n      \"query\": { \n        \"bool\": { \n          \"must\": [\n            { \"match\": { \"celebrity\":celebrity}}\n          ],\n          \"filter\": [ \n            { \"term\":  { \"genre\": genre }}\n          ]\n        }\n      }\n    }\n    res= es.search(index=_index, body=json.dumps(q))\n    if res['hits']['hits']:\n        match = res['hits']['hits'][0]\n        #print(match)\n        return match['_source']['genre_vector']\n    else:\n        return None\n        \n\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def getSimilarGenreVec( genre_vec, genre): \n    q={\n          \"query\": {\n            \"script_score\": {\n             \"query\": {\n                    \"terms\" : { \"genre\" : [genre]}\n                },\n              \"script\": {\n                \"source\": \"cosineSimilarity(params.query_vector, doc['genre_vector']) + 1.0\", \n                \"params\": {\n                  \"query_vector\": genre_vec\n                }\n              }\n            }\n          }\n        }\n    #print(json.dumps(q))\n    res= es.search(index=_index, body=q)\n\n    res= es.search(index=_index, body=json.dumps(q))\n    if res['hits']['hits']:\n        matches = res['hits']['hits']\n        #print(match)\n        results=[]\n        for match in matches:\n            results.append( { 'genre': genre, 'celebrity': match['_source']['celebrity'], 'score': match['_score']})\n        return (results) \n    else:\n        return None\n\n    \n\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# 'Comedy, Animation, Action, Documentary, Short, Adventure, Drama, Biography, Music, Thriller, Horror, Mystery, Crime, Sport, Musical, , Family, Game-Show, Reality-TV, Fantasy, Romance, Sci-Fi, History, War, Western, News, Film-Noir'\ncelebritySearch = 'Robert Downey Jr.'\ngenreSearch='Adventure'\n\ngetCelbGenre(celebritySearch)\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "genreVec = getCelbGenreVec(celebritySearch, genreSearch)\ngetSimilarGenreVec( genreVec, genreSearch)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Recommendations Celebrity alterative based on their past genre movies.\n\n* For a given Celebrity, reference all the genre we have information on. Retrieve the genre vector space based on \nthe list of movies plots the actor performed in the past.\n* Calculate the cosine distince and recommend other celebrities who performed in similar movies based on their plots "}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "resByDrama=[]\n\nfor genreSearch in getCelbGenre(celebritySearch):\n    genreVec = getCelbGenreVec(celebritySearch, genreSearch)\n    genreRecs = getSimilarGenreVec( genreVec, genreSearch)\n    # Remove the search celebrirty from the recomendations\n    resByDrama = resByDrama+ [i  for i in genreRecs if i['celebrity']!= celebritySearch ] \n    \nresByDrama", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "from IPython.display import Image, HTML, display\n\ndisplay(HTML(\"<h2>Get similar celebrities for: %s</h2>\"% celebritySearch))\n\npd.DataFrame.from_dict(resByDrama, dtype=str)   ", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "\nresultDF = pd.DataFrame.from_dict(resByDrama, dtype=str)   \n\nresultDF.info()", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# Data Visualize Cluster", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from sklearn.cluster import DBSCAN, KMeans\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nX = np.array([float(x) for x in xin[i]])\n\nclust = KMeans().fit(X)\ny_kmeans = KMeans.predict(X)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}